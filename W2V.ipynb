{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import word2vecReader\n",
    "from scipy.stats import mode\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from numpy import std\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from textblob.taggers import PatternTagger\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from ParserSarcasmDetector import ParserSarcasmDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sarc = pd.read_csv(\"data/SarcasmAddData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "stdin, stdout = sys.stdin, sys.stdout\n",
    "reload(sys)\n",
    "sys.stdin, sys.stdout = stdin, stdout\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = word2vecReader.Word2Vec.load_word2vec_format('word2vec_twitter_model/word2vec_twitter_model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "affect = pd.read_csv(\"sp_files/Ratings_Warriner_et_al-2.csv\")\n",
    "keys = list(affect[\"Word\"])\n",
    "values = list(affect[\"V.Mean.Sum\"])\n",
    "affect_scores = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_set(f):\n",
    "    s = set()\n",
    "    set_file = open(f, \"r\")\n",
    "    for line in set_file:\n",
    "        l = line.split()\n",
    "        s.add(l[0])\n",
    "    return s\n",
    "\n",
    "swear_words_set = get_set(\"sp_files/swear_words_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_strength_dict(f, val):\n",
    "    s_d = {}\n",
    "    s_file = open(f, \"r\")\n",
    "    for line in s_file:\n",
    "        l = line.split()\n",
    "        if val:\n",
    "            s_d[re.sub(r\"\\*\",r\"\",l[0])] = int(l[1])\n",
    "        else:\n",
    "            s_d[re.sub(r\"\\*\",r\"\",l[0])] = 0\n",
    "    return s_d\n",
    "\n",
    "sentiments_dict = get_strength_dict(\"sp_files/SentimentLookupTable.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_strength_list(f):\n",
    "    s_l = []\n",
    "    s_file = open(f, \"r\")\n",
    "    for line in s_file:\n",
    "        s_l.append(line.strip())\n",
    "    return s_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "booster_dict = get_strength_dict(\"sp_files/BoosterWordList.txt\", True)\n",
    "idioms_dict = get_strength_list(\"sp_files/EC-Idioms-Intermediate-Advanced-3.txt\")\n",
    "slang_dict = get_strength_dict(\"sp_files/SlangLookupTable.txt\", False)\n",
    "emoticon_dict = get_strength_list(\"sp_files/EmoticonLookupTable.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_set(filename):\n",
    "    data = pd.read_csv(filename, encoding=\"utf-8\", engine='python')\n",
    "    data = data[[\"text\", \"sarc\"]]\n",
    "    data = data[data[\"text\"].notnull()]\n",
    "    data = data[data[\"sarc\"].notnull()]\n",
    "    data[\"sarc\"] = data[\"sarc\"].apply(lambda x: int(x))\n",
    "    data = data.drop_duplicates()\n",
    "    sarc = data[data[\"sarc\"]==1]\n",
    "    not_sarc = data[data[\"sarc\"]==0][:len(data[data[\"sarc\"]==1])]\n",
    "    data_1_1 = pd.concat([sarc, not_sarc], ignore_index=True)\n",
    "    data_1_1 = shuffle(data_1_1)\n",
    "    return data_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_data_set(\"sarcasm_set_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def senti_score(x):\n",
    "    wl = WordNetLemmatizer()\n",
    "    ps = PorterStemmer()\n",
    "    if x in sentiments_dict:\n",
    "        return sentiments_dict[x]\n",
    "    lemma  = wl.lemmatize(x)\n",
    "    if lemma in sentiments_dict:\n",
    "        return sentiments_dict[lemma]\n",
    "    stem = ps.stem(x)\n",
    "    if stem in sentiments_dict:\n",
    "        return sentiments_dict[stem]\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_swear_words(t):\n",
    "    for w in t:\n",
    "        if w[0] in swear_words_set:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distribution_f(df, col):\n",
    "    df = df.copy()\n",
    "    df[col+\"mean\"]= df[col].apply(lambda x: mean(x or [0]))\n",
    "    df[col+\"median\"]= df[col].apply(lambda x: median(x or [0]))\n",
    "    df[col+\"mode\"]= df[col].apply(lambda x: mode(x or [0], axis=None).mode[0])\n",
    "    df[col+\"std\"]= df[col].apply(lambda x: std(x or [0]))\n",
    "    df[col+\"max\"]= df[col].apply(lambda x: max(x or [0]))\n",
    "    df[col+\"min\"]= df[col].apply(lambda x: min(x or [0]))\n",
    "    df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_vector(text, vec_len, m):\n",
    "    vec = [0] * vec_len\n",
    "    count = 0\n",
    "    words = TextBlob(text.lower()).words\n",
    "    for w in words:\n",
    "        if w in m:\n",
    "            vec += m[w]\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return vec\n",
    "    return vec / (1.0 * count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sim_d(words):\n",
    "    d = []\n",
    "    stop = stopwords.words('english')\n",
    "    words = [i for i in words if i not in stop]\n",
    "    #print words\n",
    "    w = 5\n",
    "    for i in range(len(words)-1):\n",
    "        if i + 1 + w > len(words):\n",
    "            r = len(words)\n",
    "        else:\n",
    "            r = i + 1 + w\n",
    "        for j in range(i+1, r):\n",
    "            if (words[i] in model) and (words[j] in model):\n",
    "                #print (words[i], words[j]), model.similarity(words[i], words[j])\n",
    "                d.append(model.similarity(words[i], words[j]))\n",
    "    return d        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_vector_f(df, vec_len, m, suf):\n",
    "    df = df.copy()\n",
    "    df[\"v\"] = df[\"text\"].apply(lambda x: get_mean_vector(x, vec_len, m))\n",
    "    for i in range(vec_len):\n",
    "        df[\"mean_v_\"+str(i+1)+suf]=df[\"v\"].apply(lambda x: x[i])\n",
    "    df = df.drop(\"v\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_similarity_f(df):\n",
    "    df = df.copy()\n",
    "    df[\"sim_d\"] = df[\"words\"].apply(lambda x: get_sim_d(x))\n",
    "    df = get_distribution_f(df, \"sim_d\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similarity(words, word):\n",
    "    new_words = [i for i in words if i in model]\n",
    "    if len(new_words) == 0:\n",
    "        return 0\n",
    "    return model.n_similarity(new_words, [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_match(x):\n",
    "    new_words = [i for i in x if i in model]\n",
    "    if len(new_words) == 0:\n",
    "        return float(senti_score(\" \"))\n",
    "    return float(senti_score(model.doesnt_match(new_words)))\n",
    "\n",
    "def get_word2vec_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"senti_not_match\"] = df[\"words\"].apply(lambda x: get_match(x))\n",
    "    df['sim_sarc'] = df[\"words\"].apply(lambda x: get_similarity(x, \"sarcasm\"))\n",
    "    df['sim_happy'] = df[\"words\"].apply(lambda x: get_similarity(x, \"happy\"))\n",
    "    df['sim_sad'] = df[\"words\"].apply(lambda x: get_similarity(x, \"sad\"))\n",
    "    df['sim_angry'] = df[\"words\"].apply(lambda x: get_similarity(x, \"angry\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iden_pronouns(t1, t2):\n",
    "    common_words = list(set(t1).intersection(set(t2)))\n",
    "    for i in common_words:\n",
    "        if i[1] != \"PRP\" or i[1] != \"PRP$\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def iden_str(t1, t2):\n",
    "    stop = stopwords.words()\n",
    "    t1 = [i[0] for i in t1 if i[1] not in stop]\n",
    "    t2 = [i[0] for i in t2 if i[1] not in stop]\n",
    "    common_words = list(set(t1).intersection(set(t2)))\n",
    "    if len(common_words) != 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_coherence(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentences = blob.sentences\n",
    "    if len(sentences) <= 1:\n",
    "        return 0\n",
    "    demonstrative = [\"this\", \"that\", \"these\", \"those\"]\n",
    "    tagged_set = [TextBlob(str(sentence).lower()).tags for sentence in sentences]\n",
    "    tagged_set = [i for i in tagged_set if len(i) != 0]\n",
    "    for i in range(len(tagged_set) - 1):\n",
    "        if iden_pronouns(tagged_set[i], tagged_set[i+1]) or iden_str(tagged_set[i], tagged_set[i+1])\\\n",
    "           or  (tagged_set[i+1][0][0] == \"the\") or (tagged_set[i+1][0][0] in demonstrative):\n",
    "                continue\n",
    "        else:\n",
    "            return -1\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(word):\n",
    "    scores = []\n",
    "    ss = senti_score(word)\n",
    "    sn = TextBlob(word + \" \").polarity * 5.0\n",
    "    if ss != 0:\n",
    "        scores.append(ss)\n",
    "    if sn != 0:\n",
    "        scores.append(sn)\n",
    "    return np.mean(scores or [0])\n",
    "        \n",
    "        \n",
    "def get_scores(filtered_text):\n",
    "    scores = [get_score(w[0]) for w in filtered_text]\n",
    "    pos_scores = [s for s in scores if s > 0]\n",
    "    neg_scores = [n for n in scores if n < 0]\n",
    "    return (sum(pos_scores or [0]), sum(neg_scores or [0]))\n",
    "    \n",
    "\n",
    "def get_emotional_scores(df):\n",
    "    df = df.copy()\n",
    "    df[\"sn\"] = df[\"tagged_words\"].apply(lambda x: get_scores(x))\n",
    "    df[\"sum_pos_score\"] = df[\"sn\"].apply(lambda x: x[0])\n",
    "    df[\"sum_neg_score\"] = df[\"sn\"].apply(lambda x: x[1])\n",
    "    df = df.drop(\"sn\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentiment_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"pos_low\"] = df[\"sum_pos_score\"].apply(lambda x: int(x<= 0))\n",
    "    df[\"pos_medium\"] = df[\"sum_pos_score\"].apply(lambda x: int((x > 0) and (x <= 1)))\n",
    "    df[\"pos_high\"] = df[\"sum_pos_score\"].apply(lambda x: int(x >= 2))\n",
    "    df[\"neg_low\"] = df[\"sum_pos_score\"].apply(lambda x: int(abs(x) <= 0))\n",
    "    df[\"neg_medium\"] = df[\"sum_pos_score\"].apply(lambda x:  int((abs(x) > 0) and (abs(x) <= 1)))\n",
    "    df[\"neg_high\"] = df[\"sum_pos_score\"].apply(lambda x: int(abs(x) >= 2))\n",
    "    df = df.drop(\"sum_pos_score\", axis=1)\n",
    "    df = df.drop(\"sum_neg_score\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rep_punct(text):\n",
    "    punct = [',', '.', '?', '!']\n",
    "    count = 0\n",
    "    for i in range(len(text)-1):\n",
    "        if (text[i] in punct) and (text[i] == text[i+1]):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def get_rep_chars(text):\n",
    "    count = 0\n",
    "    for i in range(len(text)-1):\n",
    "        if (text[i].isalpha()) and (text[i] == text[i+1]):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_punct_3_f(df, col_list):\n",
    "    df = df.copy()\n",
    "    for col in col_list:\n",
    "        df[col + \"_low\"] = df[col].apply(lambda x: int(x ==0))\n",
    "        df[col + \"_medium\"] = df[col].apply(lambda x: int((x >= 1) and (x <= 3)))\n",
    "        df[col + \"_high\"] = df[col].apply(lambda x: int(x >= 4))\n",
    "        df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_punctuation_and_sp_simbols_feature(df):\n",
    "    df = df.copy()\n",
    "    df[\"idioms_number\"] = df[\"text\"].apply(lambda x: len([i for i in idioms_dict if i in x]))\n",
    "    df[\"exlamation_number\"] = df[\"text\"].apply(lambda x: x.count(\"!\"))\n",
    "    df[\"slang_and_booster\"] = df[\"text\"].apply(lambda x: len([i for i in slang_dict if i in x.lower()]) + \n",
    "                                                             len([i for i in booster_dict if i in x.lower()]))\n",
    "    df[\"original_tagged_words\"] = df[\"text\"].apply(lambda x: TextBlob(x.decode(\"utf-8\"),pos_tagger=PatternTagger()).tags)\n",
    "    df[\"number_capitalized\"] = df[\"original_tagged_words\"].apply(lambda x: len([i for i in x if i[0].isupper()]))\n",
    "    df = df.drop(\"original_tagged_words\", axis=1)\n",
    "    df[\"emoticons_number\"] = df[\"text\"].apply(lambda x: len([i for i in emoticon_dict if i in x]))\n",
    "    df[\"rep_punc\"] = df[\"text\"].apply(lambda x: get_rep_punct(x))\n",
    "    df[\"rep_chars\"] = df[\"text\"].apply(lambda x: get_rep_chars(x))\n",
    "    df = get_punct_3_f(df, [\"idioms_number\", \"exlamation_number\", \"slang_and_booster\", \"number_capitalized\",\n",
    "                            \"emoticons_number\", \"rep_punc\", \"rep_chars\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentiment(x):\n",
    "    s = [senti_score(i[0]) for i in x]\n",
    "    return max(s or [0]) - min(s or [0])\n",
    "\n",
    "def get_affect_score(x):\n",
    "    s = [affect_scores[i[0]] for i in x if i[0] in affect_scores]\n",
    "    return max(s or [0]) - min(s or [0])\n",
    "\n",
    "def get_contrasting_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"del_sentiment\"] = df[\"tagged_words\"].apply(lambda x: get_sentiment(x))\n",
    "    df[\"del_affect\"] = df[\"tagged_words\"].apply(lambda x: get_affect_score(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_swear_words(t):\n",
    "    for w in t:\n",
    "        if w[0] in swear_words_set:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_iws(x, clf):\n",
    "    a = clf.iws(x)\n",
    "    if a == 0:\n",
    "        a = -1\n",
    "    elif a is None:\n",
    "        a = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"words\"] = df[\"text\"].apply(lambda x: TextBlob(x.lower()).words)\n",
    "    df[\"tagged_words\"] = df[\"text\"].apply(lambda x: TextBlob(x.encode(\"utf-8\").lower(),pos_tagger=PatternTagger()).tags)\n",
    "    df[\"length_d\"] = df[\"words\"].apply(lambda x: [len(i) for i in x])\n",
    "    df[\"coherence\"] = df[\"text\"].apply(lambda x: check_coherence(x))\n",
    "    df = get_distribution_f(df, \"length_d\")\n",
    "    df = get_similarity_f(df)\n",
    "    df = get_mean_vector_f(df, 400, model2, \"_mod2\")\n",
    "    df = get_word2vec_features(df)\n",
    "    df = get_emotional_scores(df)\n",
    "    df = get_sentiment_features(df)\n",
    "    clf = ParserSarcasmDetector(14)\n",
    "    df[\"iws\"] = df[\"text\"].apply(lambda x: get_iws(x, clf))\n",
    "    df = get_punctuation_and_sp_simbols_feature(df)\n",
    "    df = df.drop(\"coherence\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_f = create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(clf, trains, tests, ans_trains, ans_tests, proba):\n",
    "    f_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    accuracy_scores = []\n",
    "    auc_scores = []\n",
    "    predictions = []\n",
    "    for train, test, y_train, y_test in tqdm(zip(trains, tests, y_trains, y_tests)):\n",
    "        clf.fit(train, y_train)\n",
    "        y_pred = clf.predict(test)\n",
    "        if proba:\n",
    "            y_proba = clf.predict_proba(test)\n",
    "            #y_pred = get_pred(y_proba, thr)\n",
    "            auc_scores.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "        predictions.append(y_pred)\n",
    "        f_scores.append(f1_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    return f_scores, recall_scores, precision_scores, accuracy_scores, auc_scores, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tt_sets(trains, test, columns_f):\n",
    "    new_trains = []\n",
    "    new_tests = []\n",
    "    for train, test in tqdm(zip(trains, test)):\n",
    "        scaler = StandardScaler()\n",
    "        s_train = scaler.fit_transform(train[columns_f].astype(float))\n",
    "        s_test = scaler.transform(test[columns_f].astype(float))\n",
    "        new_trains.append(s_train)\n",
    "        new_tests.append(s_test)\n",
    "    return new_trains, new_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_trains_tests(data_f):\n",
    "    skf = KFold(len(data_f), n_folds=10, shuffle=False, random_state=None)\n",
    "    trains = []\n",
    "    tests = []\n",
    "    y_trains = []\n",
    "    y_tests = []\n",
    "    for train, test in skf:\n",
    "        trains.append(data_f.iloc[train]) \n",
    "        tests.append(data_f.iloc[test])\n",
    "        y_trains.append(data_f.sarc.iloc[train])\n",
    "        y_tests.append(data_f.sarc.iloc[test])\n",
    "    return trains, tests, y_trains, y_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trains, tests, y_trains, y_tests = get_trains_tests(data_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=2.1, probability=True)\n",
    "svm_features = data_f.columns.difference(set([\"text\",'tagged_words','words', \"sarc\", \"sim_d\", \"v\"]))\n",
    "svm_trains, svm_tests = create_tt_sets(trains, tests, svm_features)\n",
    "svm_f1, svm_recall, svm_pr, svm_acc, svm_auc, svm_predict = evaluation(clf, svm_trains, svm_tests,\n",
    "                                                                       y_trains, y_tests, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm avg f1: 0.783096988418\n",
      "svm avg recall: 0.805587395072\n",
      "svm avg precision: 0.762138818575\n",
      "svm avg accuracy: 0.7771219171\n",
      "svm avg auc: 0.855148606635\n"
     ]
    }
   ],
   "source": [
    "print \"svm avg f1:\", np.mean(svm_f1)\n",
    "print \"svm avg recall:\", np.mean(svm_recall)\n",
    "print \"svm avg precision:\", np.mean(svm_pr)\n",
    "print \"svm avg accuracy:\", np.mean(svm_acc)\n",
    "print \"svm avg auc:\", np.mean(svm_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_sets():\n",
    "    trains = []\n",
    "    tests = []\n",
    "    y_trains = []\n",
    "    y_tests = []\n",
    "    for i in tqdm(range(10)):\n",
    "        train = pd.read_csv(\"data_train_kf_\"+str(i)+\".csv\", encoding=\"utf-8\")\n",
    "        test = pd.read_csv(\"data_test_kf_\"+str(i)+\".csv\", encoding=\"utf-8\")\n",
    "        x_train = create_features(train)\n",
    "        trains.append(x_train)\n",
    "        y_train = x_train.sarc\n",
    "        y_trains.append(y_train)\n",
    "        x_test = create_features(test)\n",
    "        tests.append(x_test)\n",
    "        y_test = x_test.sarc\n",
    "        y_tests.append(y_test)\n",
    "    return trains, tests, y_trains, y_tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trains, tests, y_trains, y_tests = load_data_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=2.1, probability=True)\n",
    "svm_features = data_f.columns.difference(set([\"text\",'tagged_words','words', \"sarc\", \"sim_d\", \"v\"]))\n",
    "svm_trains, svm_tests = create_tt_sets(trains, tests, svm_features)\n",
    "svm_f1, svm_recall, svm_pr, svm_acc, svm_auc, svm_predict = evaluation(clf, svm_trains, svm_tests,\n",
    "                                                                       y_trains, y_tests, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_answers(alg_name, prd):\n",
    "    i = 0\n",
    "    for y_pr in prd:\n",
    "        pd.Series(list(y_pr)).to_csv(alg_name +\"_y_prd_kf_\"+str(i)+\".csv\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store_answers(\"new\", svm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm avg f1: 0.782383742664\n",
      "svm avg recall: 0.803472599496\n",
      "svm avg precision: 0.762758242897\n",
      "svm avg accuracy: 0.776680090885\n",
      "svm avg auc: 0.855627349172\n"
     ]
    }
   ],
   "source": [
    "print \"svm avg f1:\", np.mean(svm_f1)\n",
    "print \"svm avg recall:\", np.mean(svm_recall)\n",
    "print \"svm avg precision:\", np.mean(svm_pr)\n",
    "print \"svm avg accuracy:\", np.mean(svm_acc)\n",
    "print \"svm avg auc:\", np.mean(svm_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
