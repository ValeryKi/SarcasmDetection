{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from scipy.stats import mode\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from numpy import std\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from senticnet.senticnet import Senticnet\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sps\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob.taggers import PatternTagger\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_set(filename):\n",
    "    data = pd.read_csv(filename, encoding=\"utf-8\", engine='python')\n",
    "    data = data[[\"text\", \"sarc\"]]\n",
    "    data = data[data[\"text\"].notnull()]\n",
    "    data = data[data[\"sarc\"].notnull()]\n",
    "    data[\"sarc\"] = data[\"sarc\"].apply(lambda x: int(x))\n",
    "    data = data.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    sarc = data[data[\"sarc\"]==1]\n",
    "    not_sarc = data[data[\"sarc\"]==0][:len(data[data[\"sarc\"]==1])]\n",
    "    data_1_1 = pd.concat([sarc, not_sarc], ignore_index=True)\n",
    "    data_1_1 = shuffle(data_1_1)\n",
    "    return data_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_strength_dict(f, val):\n",
    "    s_d = {}\n",
    "    s_file = open(f, \"r\")\n",
    "    for line in s_file:\n",
    "        l = line.split()\n",
    "        if val:\n",
    "            s_d[re.sub(r\"\\*\",r\"\",l[0])] = int(l[1])\n",
    "        else:\n",
    "            s_d[re.sub(r\"\\*\",r\"\",l[0])] = 0\n",
    "    return s_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_strength_list(f):\n",
    "    s_l = []\n",
    "    s_file = open(f, \"r\")\n",
    "    for line in s_file:\n",
    "        s_l.append(line.strip())\n",
    "    return s_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "booster_dict = get_strength_dict(\"sp_files/BoosterWordList.txt\", True)\n",
    "idioms_dict = get_strength_list(\"sp_files/EC-Idioms-Intermediate-Advanced-3.txt\")\n",
    "slang_dict = get_strength_dict(\"sp_files/SlangLookupTable.txt\", False)\n",
    "emoticon_dict = get_strength_list(\"sp_files/EmoticonLookupTable.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiments_dict = get_strength_dict(\"sp_files/SentimentLookupTable.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def senti_score(x):\n",
    "    wl = WordNetLemmatizer()\n",
    "    ps = PorterStemmer()\n",
    "    if x in sentiments_dict:\n",
    "        return sentiments_dict[x]\n",
    "    lemma  = wl.lemmatize(x)\n",
    "    if lemma in sentiments_dict:\n",
    "        return sentiments_dict[lemma]\n",
    "    stem = ps.stem(x)\n",
    "    if stem in sentiments_dict:\n",
    "        return sentiments_dict[stem]\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_data_set(\"sarcasm_set_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tagging(text):\n",
    "    text_and_tags = PatternTagger().tag(text.decode(\"utf-8\").lower())\n",
    "    return text_and_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iden_pronouns(t1, t2):\n",
    "    common_words = list(set(t1).intersection(set(t2)))\n",
    "    for i in common_words:\n",
    "        if i[1] != \"PRP\" or i[1] != \"PRP$\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def iden_str(t1, t2):\n",
    "    stop = stopwords.words()\n",
    "    t1 = [i[0] for i in t1 if i[1] not in stop]\n",
    "    t2 = [i[0] for i in t2 if i[1] not in stop]\n",
    "    common_words = list(set(t1).intersection(set(t2)))\n",
    "    if len(common_words) != 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_coherence(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentences = blob.sentences\n",
    "    if len(sentences) <= 1:\n",
    "        return 0\n",
    "    demonstrative = [\"this\", \"that\", \"these\", \"those\"]\n",
    "    tagged_set = [TextBlob(str(sentence).lower()).tags for sentence in sentences]\n",
    "    tagged_set = [i for i in tagged_set if len(i) != 0]\n",
    "    for i in range(len(tagged_set) - 1):\n",
    "        if iden_pronouns(tagged_set[i], tagged_set[i+1]) or iden_str(tagged_set[i], tagged_set[i+1])\\\n",
    "           or  (tagged_set[i+1][0][0] == \"the\") or (tagged_set[i+1][0][0] in demonstrative):\n",
    "                continue\n",
    "        else:\n",
    "            return -1\n",
    "    return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_score(word):\n",
    "    scores = []\n",
    "    ss = senti_score(word)\n",
    "    sn = TextBlob(word + \" \").polarity * 5.0\n",
    "    if ss != 0:\n",
    "        scores.append(ss)\n",
    "    if sn != 0:\n",
    "        scores.append(sn)\n",
    "    return np.mean(scores or [0])\n",
    "        \n",
    "        \n",
    "def get_scores(filtered_text):\n",
    "    scores = [get_score(w[0]) for w in filtered_text]\n",
    "    pos_scores = [s for s in scores if s > 0]\n",
    "    neg_scores = [n for n in scores if n < 0]\n",
    "    return (sum(pos_scores or [0]), sum(neg_scores or [0]))\n",
    "    \n",
    "\n",
    "def get_emotional_scores(df):\n",
    "    df = df.copy()\n",
    "    df[\"sn\"] = df[\"tagged_words\"].apply(lambda x: get_scores(x))\n",
    "    df[\"sum_pos_score\"] = df[\"sn\"].apply(lambda x: x[0])\n",
    "    df[\"sum_neg_score\"] = df[\"sn\"].apply(lambda x: x[1])\n",
    "    df = df.drop(\"sn\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contra(coh, pos, neg):\n",
    "    if coh == 0:\n",
    "        if (abs(pos) > 0) and (abs(neg) > 0):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def get_contra_coher(coh, pos, neg):\n",
    "    if coh == 1:\n",
    "        if (abs(pos) > 0) and (abs(neg) > 0):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def get_contraditional_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"contra\"] = df[[\"coherence\", \"sum_pos_score\", \n",
    "                       \"sum_neg_score\"]].apply(lambda x: get_contra(x[0], x[1], x[2]),axis=1)\n",
    "    df[\"contra_coher\"] =  df[[\"coherence\", \"sum_pos_score\",\n",
    "                              \"sum_neg_score\"]].apply(lambda x: get_contra_coher(x[0], x[1], x[2]),axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentiment_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"pos_low\"] = df[\"sum_pos_score\"].apply(lambda x: int(x<= 0))\n",
    "    df[\"pos_medium\"] = df[\"sum_pos_score\"].apply(lambda x: int((x > 0) and (x <= 1)))\n",
    "    df[\"pos_high\"] = df[\"sum_pos_score\"].apply(lambda x: int(x >= 2))\n",
    "    df[\"neg_low\"] = df[\"sum_pos_score\"].apply(lambda x: int(abs(x) <= 0))\n",
    "    df[\"neg_medium\"] = df[\"sum_pos_score\"].apply(lambda x:  int((abs(x) > 0) and (abs(x) <= 1)))\n",
    "    df[\"neg_high\"] = df[\"sum_pos_score\"].apply(lambda x: int(abs(x) >= 2))\n",
    "    df = df.drop(\"sum_pos_score\", axis=1)\n",
    "    df = df.drop(\"sum_neg_score\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rep_punct(text):\n",
    "    punct = [',', '.', '?', '!']\n",
    "    count = 0\n",
    "    for i in range(len(text)-1):\n",
    "        if (text[i] in punct) and (text[i] == text[i+1]):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def get_rep_chars(text):\n",
    "    count = 0\n",
    "    for i in range(len(text)-1):\n",
    "        if (text[i].isalpha()) and (text[i] == text[i+1]):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_punct_3_f(df, col_list):\n",
    "    df = df.copy()\n",
    "    for col in col_list:\n",
    "        df[col + \"_low\"] = df[col].apply(lambda x: int(x ==0))\n",
    "        df[col + \"_medium\"] = df[col].apply(lambda x: int((x >= 1) and (x <= 3)))\n",
    "        df[col + \"_high\"] = df[col].apply(lambda x: int(x >= 4))\n",
    "        df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_punctuation_and_sp_simbols_feature(df):\n",
    "    df = df.copy()\n",
    "    df[\"idioms_number\"] = df[\"text\"].apply(lambda x: len([i for i in idioms_dict if i in x]))\n",
    "    df[\"exlamation_number\"] = df[\"text\"].apply(lambda x: x.count(\"!\"))\n",
    "    df[\"slang_and_booster\"] = df[\"text\"].apply(lambda x: len([i for i in slang_dict if i in x.lower()]) + \n",
    "                                                             len([i for i in booster_dict if i in x.lower()]))\n",
    "    df[\"original_tagged_words\"] = df[\"text\"].apply(lambda x: TextBlob(x.decode(\"utf-8\"),pos_tagger=PatternTagger()).tags)\n",
    "    df[\"number_capitalized\"] = df[\"text\"].apply(lambda x: len([i for i in x if i[0].isupper()]))\n",
    "    df = df.drop(\"original_tagged_words\", axis=1)\n",
    "    df[\"emoticons_number\"] = df[\"text\"].apply(lambda x: len([i for i in emoticon_dict if i in x]))\n",
    "    df[\"rep_punc\"] = df[\"text\"].apply(lambda x: get_rep_punct(x))\n",
    "    df[\"rep_chars\"] = df[\"text\"].apply(lambda x: get_rep_chars(x))\n",
    "    df = get_punct_3_f(df, [\"idioms_number\", \"exlamation_number\", \"slang_and_booster\", \"number_capitalized\",\n",
    "                            \"emoticons_number\", \"rep_punc\", \"rep_chars\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"tagged_text\"] = df[\"text\"].apply(lambda x: get_tagging(x))\n",
    "    df[\"tagged_words\"] = df[\"text\"].apply(lambda x: TextBlob(x.encode(\"utf-8\").lower(),pos_tagger=PatternTagger()).tags)\n",
    "    df[\"coherence\"] = df[\"text\"].apply(lambda x: check_coherence(x))\n",
    "    df = get_emotional_scores(df)\n",
    "    df = get_contraditional_features(df)\n",
    "    df = get_sentiment_features(df)\n",
    "    df = get_punctuation_and_sp_simbols_feature(df)\n",
    "    df = df.drop(\"tagged_text\", axis=1)\n",
    "    df = df.drop(\"tagged_words\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_f = create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scales_features(train, test, columns):\n",
    "    scaler = StandardScaler()\n",
    "    l_train = scaler.fit_transform(train[columns].astype(float))\n",
    "    l_test = scaler.transform(test[columns].astype(float))\n",
    "    return l_train, l_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_n_gram_features(train, test, column, n_range):\n",
    "    trigram_vectorizer = CountVectorizer(ngram_range=(1, n_range), min_df=1)\n",
    "    X_train = trigram_vectorizer.fit_transform(train[column])\n",
    "    X_test = trigram_vectorizer.transform(test[column])\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_full_feature_set(train, test, columns_f, n_gram_col, r):\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    s_train, s_test = get_scales_features(train, test, columns_f)\n",
    "    ngram_train, ngram_test = get_n_gram_features(train, test, n_gram_col, r)\n",
    "    s_train = sps.hstack((s_train, ngram_train))\n",
    "    s_test = sps.hstack((s_test, ngram_test))\n",
    "    return s_train, s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tt_sets(trains, test, columns_f, n_gram_col, r):\n",
    "    new_trains = []\n",
    "    new_tests = []\n",
    "    for train, test in tqdm(zip(trains, test)):\n",
    "        train, test = get_full_feature_set(train, test, columns_f, n_gram_col, r)\n",
    "        new_trains.append(train)\n",
    "        new_tests.append(test)\n",
    "    return new_trains, new_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred(y_proba, thr):\n",
    "    y_pr = []\n",
    "    for i in y_proba[:,1]:\n",
    "        if i < thr:\n",
    "            y_pr.append(0)\n",
    "        else:\n",
    "            y_pr.append(1)\n",
    "    return y_pr\n",
    "\n",
    "\n",
    "def evaluation(clf, trains, tests, ans_trains, ans_tests, proba):\n",
    "    f_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    accuracy_scores = []\n",
    "    auc_scores = []\n",
    "    predictions = []\n",
    "    probas = []\n",
    "    for train, test, y_train, y_test in tqdm(zip(trains, tests, y_trains, y_tests)):\n",
    "        clf.fit(train, y_train)\n",
    "        y_pred = clf.predict(test)\n",
    "        if proba:\n",
    "            y_proba = clf.predict_proba(test)\n",
    "            probas.append(y_proba)\n",
    "            #y_pred = get_pred(y_proba, thr)\n",
    "            auc_scores.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "        predictions.append(y_pred)\n",
    "        f_scores.append(f1_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    return f_scores, recall_scores, precision_scores, accuracy_scores, auc_scores, predictions, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_trains_tests(data_f):\n",
    "    skf = KFold(len(data_f), n_folds=10, shuffle=False, random_state=None)\n",
    "    trains = []\n",
    "    tests = []\n",
    "    y_trains = []\n",
    "    y_tests = []\n",
    "    data_1_1 = shuffle(data_f)\n",
    "    for train, test in skf:\n",
    "        trains.append(data_f.iloc[train]) \n",
    "        tests.append(data_f.iloc[test])\n",
    "        y_trains.append(data_f.sarc.iloc[train])\n",
    "        y_tests.append(data_f.sarc.iloc[test])\n",
    "    return trains, tests, y_trains, y_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "trains, tests, y_trains, y_tests = get_trains_tests(data_f)\n",
    "clf = LogisticRegression(C=0.6)\n",
    "log_features = data_f.columns.difference(set([\"text\", \"sarc\", \"coherence\"]))\n",
    "log_trains, log_tests = create_tt_sets(trains, tests, log_features, \"text\", 3)\n",
    "log_f1, log_recall, log_pr, log_acc, log_auc, log_predict, log_probas = evaluation(clf, log_trains, log_tests,\n",
    "                                                                       y_trains, y_tests, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log avg f1: 0.745852386884\n",
      "log avg recall: 0.755726758129\n",
      "log avg precision: 0.736679766066\n",
      "log avg accuracy: 0.742778943527\n",
      "log avg auc: 0.825570028267\n"
     ]
    }
   ],
   "source": [
    "print \"log avg f1:\", np.mean(log_f1)\n",
    "print \"log avg recall:\", np.mean(log_recall)\n",
    "print \"log avg precision:\", np.mean(log_pr)\n",
    "print \"log avg accuracy:\", np.mean(log_acc)\n",
    "print \"log avg auc:\", np.mean(log_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_sets():\n",
    "    trains = []\n",
    "    tests = []\n",
    "    y_trains = []\n",
    "    y_tests = []\n",
    "    for i in tqdm(range(10)):\n",
    "        train = pd.read_csv(\"data_train_kf_\"+str(i)+\".csv\", encoding=\"utf-8\")\n",
    "        test = pd.read_csv(\"data_test_kf_\"+str(i)+\".csv\", encoding=\"utf-8\")\n",
    "        x_train = create_features(train)\n",
    "        trains.append(x_train)\n",
    "        y_train = x_train.sarc\n",
    "        y_trains.append(y_train)\n",
    "        x_test = create_features(test)\n",
    "        tests.append(x_test)\n",
    "        y_test = x_test.sarc\n",
    "        y_tests.append(y_test)\n",
    "    return trains, tests, y_trains, y_tests    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "trains, tests, y_trains, y_tests = load_data_sets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.6)\n",
    "log_features = trains[0].columns.difference(set([\"text\", \"sarc\", \"coherence\"]))\n",
    "log_trains, log_tests = create_tt_sets(trains, tests, log_features, \"text\", 3)\n",
    "log_f1, log_recall, log_pr, log_acc, log_auc, log_predict, log_probas = evaluation(clf, log_trains, log_tests,\n",
    "                                                                       y_trains, y_tests, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def store_answers(alg_name, prd, probas):\n",
    "    i = 0\n",
    "    for y_pr, y_proba in zip(prd, probas):\n",
    "        pd.Series(list(y_pr)).to_csv(alg_name +\"_y_prd_kf_\"+str(i)+\".csv\")\n",
    "        pd.Series(list(y_proba[:,1])).to_csv(alg_name +\"_y_prb_kf_\"+str(i)+\".csv\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store_answers(\"con\", log_predict, log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log avg f1: 0.748300806964\n",
      "log avg recall: 0.756898896539\n",
      "log avg precision: 0.740420700415\n",
      "log avg accuracy: 0.745578262324\n",
      "log avg auc: 0.823564116121\n"
     ]
    }
   ],
   "source": [
    "print \"log avg f1:\", np.mean(log_f1)\n",
    "print \"log avg recall:\", np.mean(log_recall)\n",
    "print \"log avg precision:\", np.mean(log_pr)\n",
    "print \"log avg accuracy:\", np.mean(log_acc)\n",
    "print \"log avg auc:\", np.mean(log_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
